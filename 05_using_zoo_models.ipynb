{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Florence2 as Remotely Sourced Zoo Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "\n",
    "# Load a dataset\n",
    "dataset = fo.load_dataset(\"cardd_from_hub\")\n",
    "dataset = dataset.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For context, here is the first image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "Image.open(dataset.first().filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Zoo Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone.zoo as foz \n",
    "foz.register_zoo_model_source(\"https://github.com/harpreetsahota204/florence2\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foz.download_zoo_model(\n",
    "    \"https://github.com/harpreetsahota204/florence2\",\n",
    "    model_name=\"microsoft/Florence-2-base-ft\", \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = foz.load_zoo_model(\n",
    "    \"microsoft/Florence-2-base-ft\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Florence2 for Captions\n",
    "\n",
    "The three captioning operations require no additional arguments beyond selecting the operation type. \n",
    "\n",
    "Supported `detail_level` values:\n",
    "\n",
    "* `basic`\n",
    "\n",
    "*  `detailed`\n",
    "\n",
    "* `more_detailed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.operation=\"caption\"\n",
    "model.detail_level= \"basic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.apply_model(model, label_field=\"captions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.first()['captions']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To change the caption detail level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.detail_level= \"more_detailed\"\n",
    "\n",
    "dataset.apply_model(model, label_field=\"more_detailed_captions\")\n",
    "\n",
    "dataset.first()['more_detailed_captions']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Florence2 for Detection\n",
    "\n",
    "The operations for `detection`, `dense_region_caption`, `region_proposal` don't require additional parameters for general use. \n",
    "\n",
    "However, `open_vocabulary_detection` requires a `text_prompt` parameter to guide the detection towards specific objects. \n",
    "\n",
    "\n",
    "The results are stored as Detections objects containing bounding boxes and labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.operation=\"detection\"\n",
    "\n",
    "model.detection_type=\"open_vocabulary_detection\"\n",
    "\n",
    "model.prompt=\"crack, windshield\"\n",
    "\n",
    "dataset.apply_model(model, label_field=\"ov_prompted_detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.first()['ov_prompted_detection']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or you can use the caption field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.apply_model(model, label_field=\"ov_field_detection\", prompt_field=\"captions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.first()['ov_field_detection']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For dense detections. This doesn't take a prompt as the model will detect all it can:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.operation=\"detection\"\n",
    "\n",
    "model.detection_type=\"dense_region_caption\"\n",
    "\n",
    "dataset.apply_model(model, label_field=\"dense_detections\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.first()['dense_detections']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Florence2 for Phrase Grounding\n",
    "\n",
    "Phrase grounding requires either a direct caption or a reference to a caption field. You can provide this in two ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.operation=\"phrase_grounding\"\n",
    "\n",
    "model.prompt=\"cake\"\n",
    "\n",
    "dataset.apply_model(model, label_field=\"cap_phrase_groundings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.first()['cap_phrase_groundings']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you want to use a Field of a Sample for grounding, you use the following pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.apply_model(model, \n",
    "                    label_field=\"cap_field_phrase_groundings\", \n",
    "                    prompt_field=\"more_detailed_captions\"\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.first()['cap_field_phrase_groundings']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Florence2 for Segmentation\n",
    "\n",
    "Segmentation requires either a direct expression or a reference to a field containing expressions. \n",
    "\n",
    "Similar to phrase grounding, you can provide this in two ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.operation=\"segmentation\"\n",
    "\n",
    "model.prompt=\"crack\"\n",
    "\n",
    "dataset.apply_model(model, label_field=\"prompted_segmentations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.first()['prompted_segmentations']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you want to use a Field of a Sample for grounding, you use the following pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.apply_model(model, label_field=\"sample_field_segmentations\", prompt_field=\"captions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.first()['sample_field_segmentations']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR\n",
    "\n",
    "Basic OCR (\"ocr\") requires no additional parameters and returns text strings. For OCR with region information (`ocr_with_region`), you can set `store_region_info=True` to include bounding boxes for each text region:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.operation=\"ocr\"\n",
    "\n",
    "model.store_region_info=True\n",
    "\n",
    "dataset.apply_model(model, label_field=\"text_regions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.first()['text_regions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.store_region_info=False\n",
    "\n",
    "dataset.apply_model(model, label_field=\"text_regions_no_region_info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.first()['text_regions_no_region_info']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fiftyone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
